{
  "hash": "dd57d211c64dd04acd5e0dfb8f0a7405",
  "result": {
    "markdown": "---\ntitle: \"Federated Malicious URL Detection with Flower and Transformers\"\nauthor: \"Zicun Cong\"\ndate: \"2023-04-21\"\ncategories: [code, nlp, federated learning]\nformat:\n    html:\n        code-overflow: scroll\n        code-block-border-left: true\n        code-block-bg: true\n        highlight-style: github\n        code-line-numbers: true\n---\n\n# Introduction\n\nCybersecurity is becoming increasingly important in today's digital landscape, and malicious URLs are one of the most common ways for attackers to compromise user systems. \nTraditionally, to buil a malicious URL detection model, a large amount of user data needs to be collected and stored at a centarlized server, which poses a significant privacy risk, especially for agencies with highly sensitive information, like banks. Despite the fact that individual users can create their own URL classifiers using their own data, the performance of these classifiers is often unsatisfactory due to the limited amount of data available to each user. Federated learning is a technique that enables users to collaboratively create a classifier that utilizes their large datasets while also prevsering data privacy. \n\nIn this project, we demonstrate the use of federated learning and transformers for malicious URL detection using the popuarly used [Flower](https://flower.dev) and [Hugging Face Transformers](https://huggingface.co) libraries.\n\n# Federated Learning\n\nFederated learning provides a solution to this problem by enabling multiple devices (*also named as participants*) to collaboratively train a model without sharing their raw data. In particular, federated learning is a distributed machine learning approach that enables multiple devices to collaboratively train a model without sharing their raw data. In this way, federated learning preserves the privacy of each device's data while still allowing for the development of a robust model.\n\nThe figure below demonstrate an example of federated learning. The central server maintains a machine learning model. \nIt's important to note that the model structure is common knowledge among the devices. During each epoch of model training, the central server sends the current model parameters to the devices. The devices then use these parameters to create their local models, which they train using their own local data. Once the local models have been trained, the devices send their updated model parameters back to the central server. The central server aggregates the updated parameters from all devices and uses them to update the global model.\n\nThe arrows in the figure connecting the devices to the server represent the exchange of model updates or parameters between the devices and the central server. This exchange is a critical component of federated learning, as it allows each device to contribute its own data and knowledge to the overall model without revealing its raw data to other devices or the central server. By training the model collaboratively in this way, federated learning can achieve high levels of accuracy while preserving the privacy of individual user data.\n\n|![Example of Federated Learning](federated_learning.png)|\n|:--:|\n|[Image source](https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg/)|\n\n<!-- # Transfomer -->\n\n<!-- Transformers are a type of neural networks that has shown great success in NLP tasks, such as translation and sentiment analysis. By fine-tuning pre-trained transformer models on our dataset of malicious and benign URLs, we can build a model that can accurately detect malicious URLs based on their linguistic features. -->\n\nIf you are ready, here we go to the implentation!\n\n\n\n\n# Implementation\n\nThe project consists of three major components.\n\n- `client.py` includes functions and classes used by clients for local model training.\n- `server.py` includes functions and classes used by the central server for model parameter aggregation.\n- `util.py` includes utility functions.\n\nThe code for the project, along with installation instructions for the required libraries, is available on GitHub.\n\n## Client Function\n\n\n\n```{css, echo=FALSE}\npre {\n  max-height: 300px;\n  overflow-y: auto;\n}\n```\n\n\n```python\nclass MalURLClient(fl.client.NumPyClient):\n    def __init__(self, cid, net, trainloader, valloader):\n        \"\"\"\n        cid: Client ID\n        net: Model object\n        trainloader: Dataloader for local training dataset\n        valloader: Dataloader for validation dataset\n        \"\"\"\n        self.net = net\n        self.trainloader = trainloader\n        self.testloader = testloader\n        self.valloader = valloader\n        self.cid = cid\n\n    def get_parameters(self, config):\n        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n\n    def fit(self, parameters, config):\n        set_parameters(net, parameters)\n        print(\"Training Started...\")\n        train_client(self.net, self.trainloader, epochs=1)\n        print(\"Training Finished.\")\n        return self.get_parameters(config={}), len(self.trainloader), {}\n\n    def evaluate(self, parameters, config):\n        self.net = set_parameters(net, parameters)\n        valid_loss, valid_accuracy, valid_f1 = test(self.net, self.valloader)\n        torch.cuda.empty_cache()\n        rst = {\n            'cid': int(self.cid),\n            \"valid_accuracy\": float(valid_accuracy), \n            \"valid_loss\": float(valid_loss),\n            'valid_f1': float(valid_f1),\n        }\n        return float(valid_loss), len(self.testloader), rst\n```\n\n\n\nAs in the first post, weâ€™re going to start by writing a helper file named flower_helpers.py where most of our functions will be located. Starting with imports:\n\nAll the libraries needed are here: Flower (flwr), Torch + Torchivision, Numpy, and Opacus. Some others are for typing concerns. You can notice we imported FedAvg from Flower, which is the strategy used by the library to define how weights are updated in the federated process. We need to create our strategy to adapt to the DP case. From Opacus only two things are imported: the PrivacyEngine and the sampler. The engine will let us attach it to any torch optimizer to perform the DP-SGD steps on it. As for the sampler, we will see about it in a while. The next step is defining our device for the model:\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}