[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog! This is Zicun Cong. I’m a staff data scientist at a cyber security company, where I spend my days using machine learning to protect businesses and individuals from digital threats. Prior to that I spent several years pursuasing my PhD in trustworthy machine learning with a specific focus on model interpretability and fairness. I have broad interest in end to end data science, including cloud computing, database, data mining and machine learning. Outside of work, I’m passionate about sharing my knowledge and insights with others who are interested in the intersection of data science and cyber security."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minzc",
    "section": "",
    "text": "Federated Malicious URL Detection with Flower and Transformers\n\n\n\n\n\n\n\ncode\n\n\nnlp\n\n\nfederated learning\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2023\n\n\nZicun Cong\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 20, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/fed_trans/index.html",
    "href": "posts/fed_trans/index.html",
    "title": "Federated Malicious URL Detection with Flower and Transformers",
    "section": "",
    "text": "Cybersecurity is becoming increasingly important in today’s digital landscape, and malicious URLs are one of the most common ways for attackers to compromise user systems. Traditionally, to buil a malicious URL detection model, a large amount of user data needs to be collected and stored at a centarlized server, which poses a significant privacy risk, especially for agencies with highly sensitive information, like banks. Despite the fact that individual users can create their own URL classifiers using their own data, the performance of these classifiers is often unsatisfactory due to the limited amount of data available to each user. Federated learning is a technique that enables users to collaboratively create a classifier that utilizes their large datasets while also prevsering data privacy.\nIn this project, we demonstrate the use of federated learning and transformers for malicious URL detection using the popuarly used Flower and Hugging Face Transformers libraries."
  },
  {
    "objectID": "posts/fed_trans/index.html#client-function",
    "href": "posts/fed_trans/index.html#client-function",
    "title": "Federated Malicious URL Detection with Flower and Transformers",
    "section": "Client Function",
    "text": "Client Function\nThe Client interface serves as the primary means of communication between the central server and clients. To reduce computation and communication cost, only a subset of clients are selected for model training during each epoch (also known as a communication round). The central server sends the parameters of the global model and the training instructions to the selected clients over the network. The selected clients then perform model training and evaluation using their local data and send the updated model parameters back to the central server.\nImplementing Client interface typically involves defining the following methods (although set_parameters is optional):\n\nget_parameters: return the model weight as a list of NumPy ndarrays\nset_parameters (optional): update the local model weights with the parameters received from the server\nfit: performs four operations\n\nset the local model weights\ntrain the local model\nreceive the updated local model weights\n\nevaluate test the local model\n\nclass MalURLClient(fl.client.NumPyClient):\n    def __init__(self, cid, net, trainloader, valloader):\n        \"\"\"\n        Parameters\n        ----------\n        cid: \n            Client ID\n        net: \n            Model object\n        trainloader: \n            Dataloader for local training dataset\n        valloader: \n            Dataloader for validation dataset\n        \"\"\"\n        self.net = net\n        self.trainloader = trainloader\n        self.testloader = valloader\n        self.cid = cid\n\n    def get_parameters(self, config):\n        \"\"\"\n        Parameters\n        ----------\n        config:\n            Configuration parameters requested by the server.\n            This can be used to tell the client which parameters\n            are needed along with some Scalar attributes.\n        Returns\n        -------\n        parameters: \n            The local model parameters as a list of NumPy ndarrays.\n        \"\"\"\n        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n\n    def set_parameters(self, net, parameters):\n        \"\"\"\n        Parameters\n        ----------\n        net: \n            The model to be trained\n        parameters: \n            The model paremters received from the central server\n        \"\"\"\n        params_dict = zip(net.state_dict().keys(), parameters)\n        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n        net.load_state_dict(state_dict, strict=True)\n        return net\n\n    def fit(self, parameters, config):\n        \"\"\"\n        Parameters\n        ----------\n        parameters: \n            The model parameters received from the central server\n        config: \n            Configuration parameters which allow the\n            server to influence training on the client. It can be used to communicate arbitrary values from the server to the client, for example, to set the number of (local) training epochs.\n        Returns\n        -------\n        parameters: \n            The locally updated model parameters.\n        num_examples:\n            The number of examples used for training.\n        metrics:\n            A dictionary mapping arbitrary string keys to values of type\n            bool, bytes, float, int, or str. It can be used to communicate\n            arbitrary values back to the server.\n        \"\"\"\n        set_parameters(net, parameters)\n        print(\"Training Started...\")\n        train_client(self.net, self.trainloader, epochs=1)\n        print(\"Training Finished.\")\n        return self.get_parameters(config), len(self.trainloader), {}\n\n    def evaluate(self, parameters, config):\n        \"\"\"\n        Evaluate the provided parameters using the locally held dataset.\n        Parameters\n        ----------\n        parameters :\n            The current (global) model parameters.\n        config : \n            Same as the config in fit function\n        Returns\n        -------\n        loss : float\n            The evaluation loss of the model on the local dataset.\n        num_examples : int\n            The number of examples used for evaluation.\n        metrics : Dict[str, Scalar]\n            A dictionary mapping arbitrary string keys to values of\n            type bool, bytes, float, int, or str. It can be used to\n            communicate arbitrary values back to the server.\n        \"\"\"\n        self.net = set_parameters(net, parameters)\n        # test function is defined in the utility file.\n        valid_loss, valid_accuracy, valid_f1 = test(self.net, self.valloader)\n        metrics = {\n            \"valid_accuracy\": float(valid_accuracy), \n            \"valid_loss\": float(valid_loss),\n            'valid_f1': float(valid_f1),\n        }\n        return float(valid_loss), len(self.testloader), rsmetricst\nAs in the first post, we’re going to start by writing a helper file named flower_helpers.py where most of our functions will be located. Starting with imports:\nAll the libraries needed are here: Flower (flwr), Torch + Torchivision, Numpy, and Opacus. Some others are for typing concerns. You can notice we imported FedAvg from Flower, which is the strategy used by the library to define how weights are updated in the federated process. We need to create our strategy to adapt to the DP case. From Opacus only two things are imported: the PrivacyEngine and the sampler. The engine will let us attach it to any torch optimizer to perform the DP-SGD steps on it. As for the sampler, we will see about it in a while. The next step is defining our device for the model:"
  }
]