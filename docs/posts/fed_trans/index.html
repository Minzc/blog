<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.333">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Zicun Cong">
<meta name="dcterms.date" content="2023-04-21">

<title>Zicun Cong’s Homepage - Federated Malicious URL Detection with Flower and Transformers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Zicun Cong’s Homepage</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/zicun-cong-390086a4/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text">LinkedIn</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/Minzc" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">Github</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Federated Malicious URL Detection with Flower and Transformers</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
                <div class="quarto-category">nlp</div>
                <div class="quarto-category">federated learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Zicun Cong </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 21, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#federated-learning" id="toc-federated-learning" class="nav-link" data-scroll-target="#federated-learning">Federated Learning</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a>
  <ul class="collapse">
  <li><a href="#client" id="toc-client" class="nav-link" data-scroll-target="#client">Client</a></li>
  <li><a href="#server" id="toc-server" class="nav-link" data-scroll-target="#server">Server</a></li>
  <li><a href="#utility-functions" id="toc-utility-functions" class="nav-link" data-scroll-target="#utility-functions">Utility Functions</a></li>
  <li><a href="#execution" id="toc-execution" class="nav-link" data-scroll-target="#execution">Execution</a></li>
  </ul></li>
  <li><a href="#data-and-experiment-results" id="toc-data-and-experiment-results" class="nav-link" data-scroll-target="#data-and-experiment-results">Data and Experiment Results</a>
  <ul class="collapse">
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Cybersecurity is becoming increasingly important in today’s digital landscape, and malicious URLs are one of the most common ways for attackers to compromise user systems. Traditionally, to buil a malicious URL detection model, a large amount of user data needs to be collected and stored at a centarlized server, which poses a significant privacy risk, especially for agencies with highly sensitive information, like banks. Despite the fact that individual users can create their own URL classifiers using their own data, the performance of these classifiers is often unsatisfactory due to the limited amount of data available to each user. Federated learning is a technique that enables users to collaboratively create a classifier that utilizes their large datasets while also prevsering data privacy.</p>
<p>In this project, we demonstrate the use of federated learning and transformers for malicious URL detection using the popuarly used <a href="https://flower.dev">Flower</a> and <a href="https://huggingface.co">Hugging Face Transformers</a> libraries.</p>
</section>
<section id="federated-learning" class="level1">
<h1>Federated Learning</h1>
<p>Federated learning <span class="citation" data-cites="mcmahan2017communication">(<a href="#ref-mcmahan2017communication" role="doc-biblioref">McMahan et al. 2017</a>)</span> provides a solution to this problem by enabling multiple devices (<em>also named as participants</em>) to collaboratively train a model without sharing their raw data. In particular, federated learning is a distributed machine learning approach that enables multiple devices to collaboratively train a model without sharing their raw data. In this way, federated learning preserves the privacy of each device’s data while still allowing for the development of a robust model.</p>
<p>The figure below demonstrate an example of federated learning. The central server maintains a machine learning model. It’s important to note that the model structure is common knowledge among the devices. During each epoch of model training, the central server sends the current model parameters to the devices. The devices then use these parameters to create their local models, which they train using their own local data. Once the local models have been trained, the devices send their updated model parameters back to the central server. The central server aggregates the updated parameters from all devices and uses them to update the global model.</p>
<p>The arrows in the figure connecting the devices to the server represent the exchange of model updates or parameters between the devices and the central server. This exchange is a critical component of federated learning, as it allows each device to contribute its own data and knowledge to the overall model without revealing its raw data to other devices or the central server. By training the model collaboratively in this way, federated learning can achieve high levels of accuracy while preserving the privacy of individual user data.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><img src="federated_learning.png" class="img-fluid" alt="Example of Federated Learning"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><a href="https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg/">Image source</a></td>
</tr>
</tbody>
</table>
<!-- # Transfomer -->
<!-- Transformers are a type of neural networks that has shown great success in NLP tasks, such as translation and sentiment analysis. By fine-tuning pre-trained transformer models on our dataset of malicious and benign URLs, we can build a model that can accurately detect malicious URLs based on their linguistic features. -->
<p>If you are ready, here we go to the implentation!</p>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<p>The project consists of three major components.</p>
<ul>
<li><code>client.py</code> includes functions and classes used by clients for local model training.</li>
<li><code>server.py</code> includes functions and classes used by the central server for model parameter aggregation.</li>
<li><code>util.py</code> includes utility functions.</li>
</ul>
<p>The code for the project, along with installation instructions for the required libraries, is available on GitHub <a href="https://github.com/Minzc/federated_transformer_malicious_url">Source Code</a>.</p>
<p>In the following sections, first, I’ll introduce the client implementations, followed by the server implementations. Then, I’ll discuss the utility functions. Finally, I’ll explain how to run the federated learning process.</p>
<section id="client" class="level2">
<h2 class="anchored" data-anchor-id="client">Client</h2>
<p>The <code>Client</code> interface serves as the primary means of communication between the central server and clients. To reduce computation and communication cost, only a subset of clients are selected for model training during each epoch (also known as a communication round). The central server sends the parameters of the global model and the training instructions to the selected clients over the network. The selected clients then perform model training and evaluation using their local data and send the updated model parameters back to the central server.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">class</span> MalURLClient(fl.client.NumPyClient):</span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, cid: <span class="bu">str</span>, </span>
<span id="cb1-3"><a href="#cb1-3"></a>                 net: torch.nn.Module, </span>
<span id="cb1-4"><a href="#cb1-4"></a>                 trainloader: DataLoader, </span>
<span id="cb1-5"><a href="#cb1-5"></a>                 valloader: DataLoader,</span>
<span id="cb1-6"><a href="#cb1-6"></a>                 epoch: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb1-7"><a href="#cb1-7"></a>        <span class="co">"""</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">        Initializes the class with the specified parameters.</span></span>
<span id="cb1-9"><a href="#cb1-9"></a></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co">        Parameters</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">        ----------</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co">        cid : str</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co">            A string representing the ID of the class.</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="co">        net : torch.nn.Module</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">            The neural network to use in the class.</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">        trainloader : DataLoader</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co">            The data loader for the training set.</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co">        valloader : DataLoader</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co">            The data loader for the validation set.</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="co">        epoch : int</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co">            The number of epochs to train for.</span></span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="co">        Returns</span></span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="co">        -------</span></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="co">        None</span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="co">        """</span></span>
<span id="cb1-27"><a href="#cb1-27"></a>        <span class="va">self</span>.net <span class="op">=</span> net</span>
<span id="cb1-28"><a href="#cb1-28"></a>        <span class="va">self</span>.trainloader <span class="op">=</span> trainloader</span>
<span id="cb1-29"><a href="#cb1-29"></a>        <span class="va">self</span>.valloader <span class="op">=</span> valloader</span>
<span id="cb1-30"><a href="#cb1-30"></a>        <span class="va">self</span>.cid <span class="op">=</span> cid</span>
<span id="cb1-31"><a href="#cb1-31"></a>        <span class="va">self</span>.epoch <span class="op">=</span> epoch  </span>
<span id="cb1-32"><a href="#cb1-32"></a>    <span class="co"># Other necessary functions, which will be introduced below</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Implementing <code>Client</code> interface typically involves defining the following methods (although set_parameters is optional): get_parameters, set_parameters, fit, and evaluate. Here, we have the implementation details of the four functions</p>
<p><strong>get_parameters</strong>: return the model weight as a list of NumPy ndarrays</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">def</span> get_parameters(<span class="va">self</span>, config: <span class="bu">dict</span>) <span class="op">-&gt;</span> List[np.ndarray]:</span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co">    Returns a list of the parameters of the neural network in the class.</span></span>
<span id="cb2-4"><a href="#cb2-4"></a></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co">    Parameters</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co">    ----------</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">    config : dict</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co">        A dictionary containing configuration parameters.</span></span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co">    Returns</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co">    -------</span></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co">    List[np.ndarray]</span></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="co">        A list of numpy arrays containing the parameters of the neural network.</span></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="co">    """</span></span>
<span id="cb2-15"><a href="#cb2-15"></a>    <span class="cf">return</span> [val.cpu().numpy() <span class="cf">for</span> _, val <span class="kw">in</span> <span class="va">self</span>.net.state_dict().items()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>set_parameters</strong>: update the local model weights with the parameters received from the server</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">def</span> set_parameters(net: nn.Module, parameters: List[torch.Tensor]) <span class="op">-&gt;</span> nn.Module:</span>
<span id="cb3-2"><a href="#cb3-2"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co">    Sets the parameters of a PyTorch neural network module to the specified tensors.</span></span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co">    Parameters</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co">    ----------</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">    net: nn.Module</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co">        The neural network module to set the parameters for.</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">    parameters: List[torch.Tensor]</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co">        The list of tensors to set the parameters of the neural network module to.</span></span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co">    Returns</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="co">    -------</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co">    nn.Module</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="co">        The neural network module with updated parameters.</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co">    """</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>    params_dict <span class="op">=</span> <span class="bu">zip</span>(net.state_dict().keys(), parameters)</span>
<span id="cb3-18"><a href="#cb3-18"></a>    state_dict <span class="op">=</span> OrderedDict({k: torch.Tensor(v) <span class="cf">for</span> k, v <span class="kw">in</span> params_dict})</span>
<span id="cb3-19"><a href="#cb3-19"></a>    net.load_state_dict(state_dict, strict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-20"><a href="#cb3-20"></a>    <span class="cf">return</span> net</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>fit</strong>: performs four operations 1. set the local model weights 2. train the local model 3. receive the updated local model weights</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> fit(<span class="va">self</span>, parameters, config):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co">    Parameters</span></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="co">    ----------</span></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="co">    parameters: </span></span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="co">        The model parameters received from the central server.</span></span>
<span id="cb4-7"><a href="#cb4-7"></a><span class="co">    config: </span></span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="co">        Configuration parameters which allow the</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="co">        server to influence training on the client. It can be used to communicate arbitrary values from the server to the client,</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="co">        for example, to set the number of (local) training epochs.</span></span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="co">    Returns</span></span>
<span id="cb4-12"><a href="#cb4-12"></a><span class="co">    -------</span></span>
<span id="cb4-13"><a href="#cb4-13"></a><span class="co">    parameters: </span></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="co">        The locally updated model parameters.</span></span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="co">    num_examples:</span></span>
<span id="cb4-16"><a href="#cb4-16"></a><span class="co">        The number of examples used for training.</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span class="co">    metrics:</span></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="co">        A dictionary mapping arbitrary string keys to values of type</span></span>
<span id="cb4-19"><a href="#cb4-19"></a><span class="co">        bool, bytes, float, int, or str. It can be used to communicate</span></span>
<span id="cb4-20"><a href="#cb4-20"></a><span class="co">        arbitrary values back to the server.</span></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co">    """</span></span>
<span id="cb4-22"><a href="#cb4-22"></a>    set_parameters(<span class="va">self</span>.net, parameters)</span>
<span id="cb4-23"><a href="#cb4-23"></a>    <span class="bu">print</span>(<span class="st">"Training Started..."</span>)</span>
<span id="cb4-24"><a href="#cb4-24"></a>    <span class="co"># train_client function train the local model using the client' local dataset.</span></span>
<span id="cb4-25"><a href="#cb4-25"></a>    <span class="co"># train_client function is defined in the utility file</span></span>
<span id="cb4-26"><a href="#cb4-26"></a>    train(<span class="va">self</span>.net, <span class="va">self</span>.trainloader, epochs<span class="op">=</span><span class="va">self</span>.epoch)</span>
<span id="cb4-27"><a href="#cb4-27"></a>    <span class="bu">print</span>(<span class="st">"Training Finished."</span>)</span>
<span id="cb4-28"><a href="#cb4-28"></a>    <span class="cf">return</span> <span class="va">self</span>.get_parameters(config), <span class="bu">len</span>(<span class="va">self</span>.trainloader), {}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>evaluate</strong>: evaluate the global model on the client’s local dataset</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">def</span> evaluate(<span class="va">self</span>, parameters, config):</span>
<span id="cb5-2"><a href="#cb5-2"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co">    Evaluate the provided parameters using the locally held dataset.</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="co">    Parameters</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="co">    ----------</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="co">    parameters :</span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span class="co">        The current (global) model parameters.</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="co">    config : </span></span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="co">        Same as the config in fit function.</span></span>
<span id="cb5-10"><a href="#cb5-10"></a><span class="co">    Returns</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="co">    -------</span></span>
<span id="cb5-12"><a href="#cb5-12"></a><span class="co">    loss : </span></span>
<span id="cb5-13"><a href="#cb5-13"></a><span class="co">        The evaluation loss of the model on the local dataset.</span></span>
<span id="cb5-14"><a href="#cb5-14"></a><span class="co">    num_examples : </span></span>
<span id="cb5-15"><a href="#cb5-15"></a><span class="co">        The number of examples used for evaluation.</span></span>
<span id="cb5-16"><a href="#cb5-16"></a><span class="co">    metrics : </span></span>
<span id="cb5-17"><a href="#cb5-17"></a><span class="co">        A dictionary mapping arbitrary string keys to values of</span></span>
<span id="cb5-18"><a href="#cb5-18"></a><span class="co">        type bool, bytes, float, int, or str. It can be used to</span></span>
<span id="cb5-19"><a href="#cb5-19"></a><span class="co">        communicate arbitrary values back to the server.</span></span>
<span id="cb5-20"><a href="#cb5-20"></a><span class="co">    """</span></span>
<span id="cb5-21"><a href="#cb5-21"></a>    <span class="va">self</span>.net <span class="op">=</span> set_parameters(<span class="va">self</span>.net, parameters)</span>
<span id="cb5-22"><a href="#cb5-22"></a>    <span class="co"># test function is defined in the utility file.</span></span>
<span id="cb5-23"><a href="#cb5-23"></a>    valid_loss, valid_accuracy, valid_f1 <span class="op">=</span> test(<span class="va">self</span>.net, <span class="va">self</span>.valloader)</span>
<span id="cb5-24"><a href="#cb5-24"></a>    metrics <span class="op">=</span> {</span>
<span id="cb5-25"><a href="#cb5-25"></a>        <span class="st">"valid_accuracy"</span>: <span class="bu">float</span>(valid_accuracy), </span>
<span id="cb5-26"><a href="#cb5-26"></a>        <span class="st">"valid_loss"</span>: <span class="bu">float</span>(valid_loss),</span>
<span id="cb5-27"><a href="#cb5-27"></a>        <span class="st">'valid_f1'</span>: <span class="bu">float</span>(valid_f1),</span>
<span id="cb5-28"><a href="#cb5-28"></a>    }</span>
<span id="cb5-29"><a href="#cb5-29"></a>    <span class="cf">return</span> <span class="bu">float</span>(valid_loss), <span class="bu">len</span>(<span class="va">self</span>.valloader), metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- Next, let's create an instance of our client class, and run it using the following line:

`fl.client.start_numpy_client(server_address="[::]:8080", client=CifarClient())`

The string `[::]:8080` specifies which server the client should connect to. The string `[::]` means that the server and client are running on the same machine. If we were to run a truly federated learning with the server and clients on different machines, we would need to update the server_address to point the client to the correct server. -->
</section>
<section id="server" class="level2">
<h2 class="anchored" data-anchor-id="server">Server</h2>
<p>Now that we have a way to instantiate clients, we need to create our server in order to aggregate the results. Using <code>Flower</code>, this can be done very easily by first choosing a strategy. A stratey is about how the central server update the global model using the model updates aggregated from the clients. In this project, we adopt the celebrated <code>FedAvg</code>, which will define the global weights as the average of all the clients’ weights at each round.</p>
<p>It is very important to decide how to evaluate the learned model. In federated learning, two types of evaluations are commonly used, namely, <em>centarlize evaluation</em> and <em>federated evaluation</em>. The two evaluation methods can be used at the same time.</p>
<p><strong>Centralized Evaluation (or server-side evaluation)</strong>: it works similarly to evaluation in centralized machine learning. If there’s a server-side dataset available, we can use it to evaluate the newly aggregated model after each round of training.</p>
<p><strong>Federated evaluation (or client-side evaluation)</strong>: the central server sends the newly aggregated model to a set of selected clients. Each client then evaluates the model on its local dataset and sends the evaluation metrics back to the central server. The central server aggregated the received the metrics, such as by taking the average, as the evaluation metric.</p>
<p>Federated evaluation is more powerful than centralized evaluation because it allows for evaluation over a larger set of data, which often leads to more realistic evaluation results. However, federated evaluation is more complex and requires caution. Since in each epoch, a subset of clients are randomly selected for model evaluation, the evaluation clients can change over consecutive rounds of learning, leading to unstable evaluation results even if the model remains unchanged.</p>
<p>We can mitigate the issue by selecting all clients for evaluation for stable evaluation, however, this results in large communication and computation cost, especially there are hundreds of or thousands of clients participating in the federated learning.</p>
<p>Next, let’s implement our server using the FedAvg strategy provided by <code>Flower</code>.</p>
<p><strong>evaluate</strong>: the centralized evaluation function, which will be called by the server after every epoch of federated learning.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">def</span> get_evaluate_fn(net: torch.nn.Module, testloader: DataLoader) <span class="op">-&gt;</span> Callable[[<span class="bu">int</span>, Any, <span class="bu">dict</span>], Tuple[<span class="bu">float</span>, <span class="bu">dict</span>]]:</span>
<span id="cb6-2"><a href="#cb6-2"></a>    <span class="co">"""</span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co">    Return an evaluation function for centralized evaluation.</span></span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co">    Parameters</span></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="co">    ----------</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="co">    net : torch.nn.Module</span></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="co">        The model to be evaluated.</span></span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="co">    testloader : DataLoader</span></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="co">        The dataset loader.</span></span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="co">    Returns</span></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="co">    -------</span></span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="co">    Callable[[int, Any, dict], Tuple[float, dict]]</span></span>
<span id="cb6-14"><a href="#cb6-14"></a><span class="co">        A function that evaluates the model on the given test data and returns the evaluation loss and metrics.</span></span>
<span id="cb6-15"><a href="#cb6-15"></a><span class="co">    """</span></span>
<span id="cb6-16"><a href="#cb6-16"></a>    <span class="kw">def</span> evaluate(server_round: <span class="bu">int</span>, parameters: Any, config: <span class="bu">dict</span>) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">dict</span>]:</span>
<span id="cb6-17"><a href="#cb6-17"></a>        <span class="co">"""</span></span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="co">        Evaluate the model on the given test data and return the evaluation loss and metrics.</span></span>
<span id="cb6-19"><a href="#cb6-19"></a></span>
<span id="cb6-20"><a href="#cb6-20"></a><span class="co">        Parameters</span></span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="co">        ----------</span></span>
<span id="cb6-22"><a href="#cb6-22"></a><span class="co">        server_round : int</span></span>
<span id="cb6-23"><a href="#cb6-23"></a><span class="co">            The current epoch of federated learning.</span></span>
<span id="cb6-24"><a href="#cb6-24"></a><span class="co">        parameters : Any</span></span>
<span id="cb6-25"><a href="#cb6-25"></a><span class="co">            The current (global) model parameters.</span></span>
<span id="cb6-26"><a href="#cb6-26"></a><span class="co">        config : dict</span></span>
<span id="cb6-27"><a href="#cb6-27"></a><span class="co">            Same as the config in fit.</span></span>
<span id="cb6-28"><a href="#cb6-28"></a></span>
<span id="cb6-29"><a href="#cb6-29"></a><span class="co">        Returns</span></span>
<span id="cb6-30"><a href="#cb6-30"></a><span class="co">        -------</span></span>
<span id="cb6-31"><a href="#cb6-31"></a><span class="co">        Tuple[float, dict]</span></span>
<span id="cb6-32"><a href="#cb6-32"></a><span class="co">            A tuple containing the evaluation loss and a dictionary of evaluation metrics.</span></span>
<span id="cb6-33"><a href="#cb6-33"></a><span class="co">        """</span></span>
<span id="cb6-34"><a href="#cb6-34"></a>        set_parameters(net, parameters)  <span class="co"># 'net' is the global model. Update model with the latest parameters</span></span>
<span id="cb6-35"><a href="#cb6-35"></a>        loss, accuracy, f1 <span class="op">=</span> test(net, testloader)</span>
<span id="cb6-36"><a href="#cb6-36"></a>        <span class="cf">return</span> loss, {<span class="st">"accuracy"</span>: accuracy, <span class="st">'f1'</span>: f1}</span>
<span id="cb6-37"><a href="#cb6-37"></a></span>
<span id="cb6-38"><a href="#cb6-38"></a>    <span class="cf">return</span> evaluate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>weighted_average</strong>: metric aggregation used by federated evaluation.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">def</span> weighted_average(metrics: List[Tuple[<span class="bu">int</span>, Metrics]]) <span class="op">-&gt;</span> Metrics:</span>
<span id="cb7-2"><a href="#cb7-2"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co">    Multiply accuracy of each client by number of examples used.</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">    Aggregate and return custom metric (weighted average).</span></span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">    Parameters</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co">    ----------</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">    metrics: List[Tuple[int, Metrics]]</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co">        The list of local evaluation metrics sent by clients.</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="co">        metrics[idx] is the evaluation sent by the `idx` evaluation client.</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co">        metrics[idx][0] is the number of records of the corresponding client.</span></span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="co">        metrics[idx][1] is the evaluation metrics of the corresponding clients.</span></span>
<span id="cb7-13"><a href="#cb7-13"></a></span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="co">    Returns</span></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="co">    -------</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="co">    weight_metrics: Metrics</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="co">        The weighted average of the federated evaluation.</span></span>
<span id="cb7-18"><a href="#cb7-18"></a><span class="co">    """</span></span>
<span id="cb7-19"><a href="#cb7-19"></a>    weight_metrics <span class="op">=</span> {}</span>
<span id="cb7-20"><a href="#cb7-20"></a>    <span class="cf">for</span> metric_name <span class="kw">in</span> metrics[<span class="dv">0</span>][<span class="dv">1</span>].keys():</span>
<span id="cb7-21"><a href="#cb7-21"></a>      <span class="cf">for</span> num_examples, m <span class="kw">in</span> metrics:</span>
<span id="cb7-22"><a href="#cb7-22"></a>        metric <span class="op">=</span> [num_examples <span class="op">*</span> m[metric_name] <span class="cf">for</span> num_examples, m <span class="kw">in</span> metrics]</span>
<span id="cb7-23"><a href="#cb7-23"></a>        examples <span class="op">=</span> [num_examples <span class="cf">for</span> num_examples, _ <span class="kw">in</span> metrics]</span>
<span id="cb7-24"><a href="#cb7-24"></a>        weight_metrics[metric_name] <span class="op">=</span> <span class="bu">sum</span>(metric) <span class="op">/</span> <span class="bu">sum</span>(examples)</span>
<span id="cb7-25"><a href="#cb7-25"></a>    </span>
<span id="cb7-26"><a href="#cb7-26"></a>    <span class="cf">return</span> weight_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now, we are ready to create a <code>FedAvg</code> stretegy using the above defined federated and centralized evaluation functions.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>strategy <span class="op">=</span> fl.server.strategy.FedAvg(</span>
<span id="cb8-2"><a href="#cb8-2"></a>    fraction_fit <span class="op">=</span> <span class="dv">2</span><span class="op">/</span>NUM_CLIENTS, <span class="co"># Sample 2 available clients for training in each epoch</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>    evaluate_metrics_aggregation_fn <span class="op">=</span> weighted_average, <span class="co"># Use weighted average function to aggregate the local evaluation metrics of clients. </span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    fraction_evaluate <span class="op">=</span> <span class="dv">2</span><span class="op">/</span>NUM_CLIENTS, <span class="co"># Sample 2 available clients for model evaluation</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>    evaluate_fn<span class="op">=</span>get_evaluate_fn(net, testloader)  <span class="co"># Pass the evaluation function</span></span>
<span id="cb8-6"><a href="#cb8-6"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="utility-functions" class="level2">
<h2 class="anchored" data-anchor-id="utility-functions">Utility Functions</h2>
<p>Great work! We’re halfway through our journey. In this section, we’ll implement some helper functions, including a data split function and model training and evaluation functions. Let’s get started!</p>
<p>The distributions of the local datasets held by clients can have a significant impact on the performance of the collaboratively trained model in federated learning. This is because federated learning relies on stochastic gradient descent (SGD), and the independent and identically distributed (IID) sampling of the training data is important to ensure that the stochastic gradient is an unbiased estimate of the full gradient <span class="citation" data-cites="zhao2018federated">(<a href="#ref-zhao2018federated" role="doc-biblioref">Zhao et al. 2018</a>)</span>.</p>
<p>To investigate the impact of local data distribution on the performance of the global model, we conducted experiments using two different methods to generate clients’ local data, that is, IID data generation and non-IID data generation.</p>
<p><strong>prepare_train_test_even</strong>: partition the dataset into the local training data of clients, and a server side testing data.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">def</span> _train_test_split(local_data: Dataset) <span class="op">-&gt;</span> DatasetDict:</span>
<span id="cb9-2"><a href="#cb9-2"></a>    <span class="co">"""</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="co">    This function splits a given local dataset of a client into training and validation datasets.</span></span>
<span id="cb9-4"><a href="#cb9-4"></a></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="co">    Parameters</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="co">    ----------</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co">    loca_data (Dataset): </span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co">        The local dataset of a client to be split.</span></span>
<span id="cb9-9"><a href="#cb9-9"></a></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="co">    Returns</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="co">    -------</span></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="co">    data_dict (DatasetDict): </span></span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="co">        The training and validation datasets of the client.</span></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="co">    """</span></span>
<span id="cb9-15"><a href="#cb9-15"></a>    train_val_client_split <span class="op">=</span> local_data.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span>RANDOM_SEEDS)  <span class="co"># 80% local training data, 20% local validation data</span></span>
<span id="cb9-16"><a href="#cb9-16"></a>    data_dict <span class="op">=</span> DatasetDict({</span>
<span id="cb9-17"><a href="#cb9-17"></a>                <span class="st">'train'</span>: train_val_client_split[<span class="st">'train'</span>],</span>
<span id="cb9-18"><a href="#cb9-18"></a>                <span class="st">'validation'</span>: train_val_client_split[<span class="st">'test'</span>],</span>
<span id="cb9-19"><a href="#cb9-19"></a>                })</span>
<span id="cb9-20"><a href="#cb9-20"></a>    <span class="cf">return</span> data_dict</span>
<span id="cb9-21"><a href="#cb9-21"></a></span>
<span id="cb9-22"><a href="#cb9-22"></a></span>
<span id="cb9-23"><a href="#cb9-23"></a><span class="kw">def</span> prepare_train_test_iid(raw_datasets: Dataset,  num_clients: <span class="bu">int</span>) <span class="op">-&gt;</span> Tuple[List[DatasetDict], Dataset]:</span>
<span id="cb9-24"><a href="#cb9-24"></a>    <span class="co">"""</span></span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="co">    Prepares the training and testing datasets for a federated learning scenario where the data is partitioned across </span></span>
<span id="cb9-26"><a href="#cb9-26"></a><span class="co">    multiple clients in an IID (Independent and Identically Distributed) manner.</span></span>
<span id="cb9-27"><a href="#cb9-27"></a></span>
<span id="cb9-28"><a href="#cb9-28"></a><span class="co">    Parameters</span></span>
<span id="cb9-29"><a href="#cb9-29"></a><span class="co">    ----------</span></span>
<span id="cb9-30"><a href="#cb9-30"></a><span class="co">    raw_datasets: Dataset</span></span>
<span id="cb9-31"><a href="#cb9-31"></a><span class="co">        The raw dataset containing the URLs and their corresponding labels.</span></span>
<span id="cb9-32"><a href="#cb9-32"></a></span>
<span id="cb9-33"><a href="#cb9-33"></a><span class="co">    Returns</span></span>
<span id="cb9-34"><a href="#cb9-34"></a><span class="co">    -------</span></span>
<span id="cb9-35"><a href="#cb9-35"></a><span class="co">    client_datasets: List[DatasetDict]</span></span>
<span id="cb9-36"><a href="#cb9-36"></a><span class="co">        A list of datasets for each client, each containing the training and validation subsets.</span></span>
<span id="cb9-37"><a href="#cb9-37"></a><span class="co">    server_test_dataset: Dataset</span></span>
<span id="cb9-38"><a href="#cb9-38"></a><span class="co">        The dataset used by the central server for central evaluation.</span></span>
<span id="cb9-39"><a href="#cb9-39"></a><span class="co">    """</span></span>
<span id="cb9-40"><a href="#cb9-40"></a>    train_test_split <span class="op">=</span> raw_datasets.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-41"><a href="#cb9-41"></a>    client_dataset <span class="op">=</span> train_test_split[<span class="st">'train'</span>]</span>
<span id="cb9-42"><a href="#cb9-42"></a>    server_test_dataset <span class="op">=</span> train_test_split[<span class="st">'test'</span>]</span>
<span id="cb9-43"><a href="#cb9-43"></a>    partition_size <span class="op">=</span> <span class="bu">len</span>(client_dataset) <span class="op">//</span> num_clients <span class="co"># `num_clients` is the total number of clients in the federated learning process. `partition_size` is the number of records in each client's local data.</span></span>
<span id="cb9-44"><a href="#cb9-44"></a></span>
<span id="cb9-45"><a href="#cb9-45"></a>    client_datasets <span class="op">=</span> []</span>
<span id="cb9-46"><a href="#cb9-46"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_clients):</span>
<span id="cb9-47"><a href="#cb9-47"></a>        client_split <span class="op">=</span> client_dataset.train_test_split(train_size<span class="op">=</span>partition_size)</span>
<span id="cb9-48"><a href="#cb9-48"></a>        client_dataset <span class="op">=</span> client_split[<span class="st">'test'</span>] <span class="co"># The remaining data will be divided among the other clients.</span></span>
<span id="cb9-49"><a href="#cb9-49"></a>        client_datasets.append(_train_test_split(client_split[<span class="st">'train'</span>]))</span>
<span id="cb9-50"><a href="#cb9-50"></a>    <span class="cf">return</span> client_datasets, server_test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>prepare_train_test_noniid</strong>: generate label-based non-IID distributed local datasets for clients. Assume we are working on a multi-class classification problem. A client is only assigned records from two specified categories in the dataset. For example, consider that we are working on a malicious URLs detection problem, where there are four categories, namely, benign, malicious, phishing, and defacement URLs. The first client will only have records from benign and phishing categories, the second client will only have records from benign and malicous categories, and the third client will only have records from benign and defacement categories.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> prepare_train_test_noniid(raw_datasets: Dataset, num_clients: <span class="bu">int</span>) <span class="op">-&gt;</span> Tuple[List[DatasetDict], Dataset]:</span>
<span id="cb10-2"><a href="#cb10-2"></a>    <span class="co">"""</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co">    Prepares the training and testing datasets for a federated learning scenario where the data is partitioned across </span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co">    multiple clients in a non-IID (Non-Independent and Identically Distributed) manner.</span></span>
<span id="cb10-5"><a href="#cb10-5"></a></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">    Parameters</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co">    ----------</span></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="co">    raw_datasets: Dataset</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="co">        The raw dataset containing the URLs and their corresponding labels.</span></span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="co">    num_clients: int</span></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="co">        The total number of clients in the federated learning process.</span></span>
<span id="cb10-12"><a href="#cb10-12"></a></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="co">    Returns</span></span>
<span id="cb10-14"><a href="#cb10-14"></a><span class="co">    -------</span></span>
<span id="cb10-15"><a href="#cb10-15"></a><span class="co">    client_datasets: List[DatasetDict]</span></span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="co">        A list of datasets for each client, each containing the training and validation subsets.</span></span>
<span id="cb10-17"><a href="#cb10-17"></a><span class="co">    server_test_dataset: Dataset</span></span>
<span id="cb10-18"><a href="#cb10-18"></a><span class="co">        The dataset used by the central server for central evaluation.</span></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="co">    """</span></span>
<span id="cb10-20"><a href="#cb10-20"></a></span>
<span id="cb10-21"><a href="#cb10-21"></a>    train_test_split <span class="op">=</span> raw_datasets.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-22"><a href="#cb10-22"></a>    clients_dataset, server_test_dataset <span class="op">=</span> train_test_split[<span class="st">'train'</span>], train_test_split[<span class="st">'test'</span>]</span>
<span id="cb10-23"><a href="#cb10-23"></a>    <span class="co"># label_id 0: benign</span></span>
<span id="cb10-24"><a href="#cb10-24"></a>    <span class="co"># label_id 1: malicious</span></span>
<span id="cb10-25"><a href="#cb10-25"></a>    <span class="co"># label_id 2: phishing</span></span>
<span id="cb10-26"><a href="#cb10-26"></a>    <span class="co"># label_id 3: defacement</span></span>
<span id="cb10-27"><a href="#cb10-27"></a>    whole_benign <span class="op">=</span> clients_dataset.<span class="bu">filter</span>(<span class="kw">lambda</span> x: x[<span class="st">'labels'</span>] <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb10-28"><a href="#cb10-28"></a>    benign_size_per_client <span class="op">=</span> <span class="bu">len</span>(whole_benign) <span class="op">//</span> num_clients</span>
<span id="cb10-29"><a href="#cb10-29"></a></span>
<span id="cb10-30"><a href="#cb10-30"></a>    client_datasets <span class="op">=</span> []</span>
<span id="cb10-31"><a href="#cb10-31"></a>    <span class="co"># Class 0 is benign</span></span>
<span id="cb10-32"><a href="#cb10-32"></a>    <span class="cf">for</span> cid <span class="kw">in</span> <span class="bu">range</span>(num_clients):</span>
<span id="cb10-33"><a href="#cb10-33"></a>        abnormal_urls <span class="op">=</span> clients_dataset.<span class="bu">filter</span>(<span class="kw">lambda</span> x: x[<span class="st">'labels'</span>] <span class="op">==</span> (cid <span class="op">+</span> <span class="dv">1</span>)) </span>
<span id="cb10-34"><a href="#cb10-34"></a>        client_split <span class="op">=</span> whole_benign.train_test_split(train_size<span class="op">=</span>benign_size_per_client, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-35"><a href="#cb10-35"></a>        local_benign, whole_benign <span class="op">=</span> client_split[<span class="st">'train'</span>], client_split[<span class="st">'test'</span>]</span>
<span id="cb10-36"><a href="#cb10-36"></a></span>
<span id="cb10-37"><a href="#cb10-37"></a>        local_dataset <span class="op">=</span> concatenate_datasets([local_benign, abnormal_urls])</span>
<span id="cb10-38"><a href="#cb10-38"></a>        client_datasets.append(_train_test_split(local_dataset))</span>
<span id="cb10-39"><a href="#cb10-39"></a></span>
<span id="cb10-40"><a href="#cb10-40"></a>    <span class="cf">return</span> client_datasets, server_test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For this project, we constructed our classifier using the pre-trained BERT model. To prepare the input data for the model, we used the tokenize function of BERT to tokenize each URL into a sequence of tokens compatible with the BERT model. We iterate the datasets generated from the above functions, and tokenize the datasets. The <code>tokenizer</code> is also provided by the HuggingFace Transformers library. In particular, <code>tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)</code></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">def</span> tokenize_function(record):</span>
<span id="cb11-2"><a href="#cb11-2"></a>    <span class="cf">return</span> tokenizer(record[<span class="st">"url"</span>], truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="cf">for</span> client_dataset <span class="kw">in</span> client_datasets:</span>
<span id="cb11-5"><a href="#cb11-5"></a>    tokenized_datasets <span class="op">=</span> (client_dataset</span>
<span id="cb11-6"><a href="#cb11-6"></a>                        .<span class="bu">map</span>(tokenize_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-7"><a href="#cb11-7"></a>                        .remove_columns(<span class="st">"url"</span>))</span>
<span id="cb11-8"><a href="#cb11-8"></a>    </span>
<span id="cb11-9"><a href="#cb11-9"></a>    <span class="co"># The main purpose of DataCollatorWithPadding is to dynamically pad input sequences in a batch with the padding token to match the longest sequence in that batch. </span></span>
<span id="cb11-10"><a href="#cb11-10"></a>    data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb11-11"><a href="#cb11-11"></a>    </span>
<span id="cb11-12"><a href="#cb11-12"></a>    <span class="co"># Wrap the tokenized dataset as DataLoader</span></span>
<span id="cb11-13"><a href="#cb11-13"></a>    trainloader <span class="op">=</span> DataLoader(</span>
<span id="cb11-14"><a href="#cb11-14"></a>        tokenized_datasets[<span class="st">"train"</span>],</span>
<span id="cb11-15"><a href="#cb11-15"></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb11-16"><a href="#cb11-16"></a>        batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb11-17"><a href="#cb11-17"></a>        collate_fn<span class="op">=</span>data_collator,</span>
<span id="cb11-18"><a href="#cb11-18"></a>    )</span>
<span id="cb11-19"><a href="#cb11-19"></a>    <span class="co"># Wrap test and validation dataset as DataLoader, ....</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After prepraing our datasets, next step is to define our model. For this project, we build our classifier based on the pre-trained BERT model, which can be easily implemented using the API provided by HuggingFace Transformers.</p>
<p>The created model instance <code>net</code> consists of a pre-trained distilled BERT model and a linear layer for sequence label prediction.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">def</span> init_model(num_labels: <span class="bu">int</span>, fine_tune: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>) <span class="op">-&gt;</span> torch.nn.Module:</span>
<span id="cb12-2"><a href="#cb12-2"></a>    <span class="co">"""</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co">    Initialize a BERT based sequence classifier.</span></span>
<span id="cb12-4"><a href="#cb12-4"></a></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="co">    Parameters</span></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co">    ----------</span></span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="co">    num_labels:</span></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="co">        The number of classes the model should predict.</span></span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="co">    fine_tune:</span></span>
<span id="cb12-10"><a href="#cb12-10"></a><span class="co">        If we want to fine tune the parameters of the pre-trained BERT model.</span></span>
<span id="cb12-11"><a href="#cb12-11"></a></span>
<span id="cb12-12"><a href="#cb12-12"></a><span class="co">    Returns</span></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="co">    -------</span></span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="co">    net:</span></span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="co">        A BERT-based sequence classifier model with the specified number of labels. </span></span>
<span id="cb12-16"><a href="#cb12-16"></a><span class="co">    """</span></span>
<span id="cb12-17"><a href="#cb12-17"></a>    net <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels<span class="op">=</span>num_labels).to(DEVICE)</span>
<span id="cb12-18"><a href="#cb12-18"></a></span>
<span id="cb12-19"><a href="#cb12-19"></a>    <span class="cf">if</span> fine_tune <span class="op">==</span> <span class="va">False</span>:</span>
<span id="cb12-20"><a href="#cb12-20"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> net.named_parameters():</span>
<span id="cb12-21"><a href="#cb12-21"></a>            <span class="cf">if</span> name.startswith(<span class="st">"bert"</span>): <span class="co"># choose whatever you like here</span></span>
<span id="cb12-22"><a href="#cb12-22"></a>                param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-23"><a href="#cb12-23"></a></span>
<span id="cb12-24"><a href="#cb12-24"></a>    net.train()</span>
<span id="cb12-25"><a href="#cb12-25"></a>    <span class="cf">return</span> net</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We are almost done with our implementation. The final step is to implement the training function to train our model.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">def</span> train(net: nn.Module, trainloader: DataLoader, epochs: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb13-2"><a href="#cb13-2"></a>    <span class="co">"""</span></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="co">    Train the given neural network for the specified number of epochs using the given data loader.</span></span>
<span id="cb13-4"><a href="#cb13-4"></a></span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="co">    Parameters</span></span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co">    ----------</span></span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="co">    net : nn.Module</span></span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="co">        The neural network to train.</span></span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="co">    trainloader : DataLoader</span></span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="co">        The data loader containing the training data.</span></span>
<span id="cb13-11"><a href="#cb13-11"></a><span class="co">    epochs : int</span></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="co">        The number of epochs to train for.</span></span>
<span id="cb13-13"><a href="#cb13-13"></a></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="co">    Returns</span></span>
<span id="cb13-15"><a href="#cb13-15"></a><span class="co">    -------</span></span>
<span id="cb13-16"><a href="#cb13-16"></a><span class="co">    None</span></span>
<span id="cb13-17"><a href="#cb13-17"></a><span class="co">    """</span></span>
<span id="cb13-18"><a href="#cb13-18"></a></span>
<span id="cb13-19"><a href="#cb13-19"></a>    optimizer <span class="op">=</span> AdamW(net.parameters(), lr<span class="op">=</span><span class="fl">5e-5</span>)</span>
<span id="cb13-20"><a href="#cb13-20"></a></span>
<span id="cb13-21"><a href="#cb13-21"></a>    <span class="cf">for</span> _ <span class="kw">in</span> tqdm.tqdm(<span class="bu">range</span>(epochs), desc<span class="op">=</span><span class="st">'epoch'</span>):</span>
<span id="cb13-22"><a href="#cb13-22"></a>      net.train()</span>
<span id="cb13-23"><a href="#cb13-23"></a>      total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-24"><a href="#cb13-24"></a>      <span class="cf">for</span> batch <span class="kw">in</span> tqdm.tqdm(trainloader, desc<span class="op">=</span><span class="st">'iterate data'</span>):</span>
<span id="cb13-25"><a href="#cb13-25"></a>          batch <span class="op">=</span> {k: v.to(DEVICE) <span class="cf">for</span> k, v <span class="kw">in</span> batch.items()}</span>
<span id="cb13-26"><a href="#cb13-26"></a>          outputs <span class="op">=</span> net(<span class="op">**</span>batch)</span>
<span id="cb13-27"><a href="#cb13-27"></a>          logits <span class="op">=</span> outputs.get(<span class="st">"logits"</span>)</span>
<span id="cb13-28"><a href="#cb13-28"></a>          loss_fct <span class="op">=</span> nn.CrossEntropyLoss(</span>
<span id="cb13-29"><a href="#cb13-29"></a>                        weight<span class="op">=</span>torch.tensor([<span class="fl">1.0</span>, <span class="fl">10.0</span>, <span class="fl">10.0</span>, <span class="fl">10.0</span>], </span>
<span id="cb13-30"><a href="#cb13-30"></a>                        device<span class="op">=</span>DEVICE)</span>
<span id="cb13-31"><a href="#cb13-31"></a>                      )</span>
<span id="cb13-32"><a href="#cb13-32"></a>          labels <span class="op">=</span> batch.get(<span class="st">"labels"</span>)</span>
<span id="cb13-33"><a href="#cb13-33"></a>          loss <span class="op">=</span> loss_fct(logits.view(<span class="op">-</span><span class="dv">1</span>, NUM_LABELS), labels.view(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb13-34"><a href="#cb13-34"></a>          loss.backward()</span>
<span id="cb13-35"><a href="#cb13-35"></a>          optimizer.step()</span>
<span id="cb13-36"><a href="#cb13-36"></a>          optimizer.zero_grad()</span>
<span id="cb13-37"><a href="#cb13-37"></a>          total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb13-38"><a href="#cb13-38"></a>      </span>
<span id="cb13-39"><a href="#cb13-39"></a>    torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="execution" class="level2">
<h2 class="anchored" data-anchor-id="execution">Execution</h2>
<p>Now that we have completed the implementation of our federated learning system, it’s time to put it to the test. Now that we have completed the implementation of our federated learning system, it’s time to put it to the test. Consider we aim to simulate a federated learning system with 10 clients on a single machine. Flower provides two ways to run the system: (1) Flower launches 10 instances of FlowerClient on different machines or servers; (2) Flower offers a way to simulate a federated learning system with multiple clients on a single machine by creating FlowerClient instances only when necessary for training or evaluation. This helps prevent memory exhaustion. To enable this function, we need to implement a <code>client_fn</code> function that creates a FlowerClient instance on demand.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">def</span> get_client_fn(client_dataloaders):</span>
<span id="cb14-2"><a href="#cb14-2"></a>    <span class="co">"""</span></span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="co">    Return the function to create a client</span></span>
<span id="cb14-4"><a href="#cb14-4"></a></span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="co">    Parameters</span></span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="co">    ----------</span></span>
<span id="cb14-7"><a href="#cb14-7"></a><span class="co">    client_dataloaders:</span></span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="co">        Dataloader of the training data of all clients</span></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="co">    """</span></span>
<span id="cb14-10"><a href="#cb14-10"></a>    <span class="kw">def</span> client_fn(cid):</span>
<span id="cb14-11"><a href="#cb14-11"></a>        <span class="co">"""</span></span>
<span id="cb14-12"><a href="#cb14-12"></a><span class="co">        Create a client instance</span></span>
<span id="cb14-13"><a href="#cb14-13"></a><span class="co">        </span></span>
<span id="cb14-14"><a href="#cb14-14"></a><span class="co">        Parameters</span></span>
<span id="cb14-15"><a href="#cb14-15"></a><span class="co">        -----------</span></span>
<span id="cb14-16"><a href="#cb14-16"></a><span class="co">        cid:</span></span>
<span id="cb14-17"><a href="#cb14-17"></a><span class="co">            The client ID</span></span>
<span id="cb14-18"><a href="#cb14-18"></a><span class="co">        """</span></span>
<span id="cb14-19"><a href="#cb14-19"></a>        <span class="cf">return</span> MalURLClient(cid, net, client_dataloaders[<span class="bu">int</span>(cid)][<span class="st">'train'</span>], client_dataloaders[<span class="bu">int</span>(cid)][<span class="st">'validation'</span>], testloader)</span>
<span id="cb14-20"><a href="#cb14-20"></a>    </span>
<span id="cb14-21"><a href="#cb14-21"></a>    <span class="cf">return</span> client_fn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this project, we focus on the second option of simulation. To start the simulatoin, we only a simple call the build-in function <code>start_simulation</code>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Start simulation</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>fl.simulation.start_simulation(</span>
<span id="cb15-3"><a href="#cb15-3"></a>    client_fn<span class="op">=</span>get_client_fn(client_dataloaders),</span>
<span id="cb15-4"><a href="#cb15-4"></a>    num_clients<span class="op">=</span>NUM_CLIENTS,</span>
<span id="cb15-5"><a href="#cb15-5"></a>    config<span class="op">=</span>fl.server.ServerConfig(num_rounds<span class="op">=</span><span class="dv">5</span>),</span>
<span id="cb15-6"><a href="#cb15-6"></a>    strategy<span class="op">=</span>strategy, <span class="co"># Server side strategy discussed in Section Server</span></span>
<span id="cb15-7"><a href="#cb15-7"></a>    client_resources<span class="op">=</span>client_resources,</span>
<span id="cb15-8"><a href="#cb15-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="data-and-experiment-results" class="level1">
<h1>Data and Experiment Results</h1>
<p>We conduct experiments using a public benchmark <a href="https://www.kaggle.com/datasets/sid321axn/malicious-urls-dataset">dataset for abnormal URL detection</a>. Some statistics of the dataset is shown in the following table.</p>
<table class="table">
<thead>
<tr class="header">
<th>Category</th>
<th>Count</th>
<th>Ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>benign</td>
<td>47,766</td>
<td>73.36%</td>
</tr>
<tr class="even">
<td>defacement</td>
<td>11,899</td>
<td>18.28%</td>
</tr>
<tr class="odd">
<td>phishing</td>
<td>3,884</td>
<td>5.97%</td>
</tr>
<tr class="even">
<td>malware</td>
<td>1,561</td>
<td>2.40%</td>
</tr>
</tbody>
</table>
<p>In each experiment, we perform ten communication rounds. By default, there are ten participants, and two participants are selected for model training per round. The selected participants execute one epoch of training on their local models.</p>
<p>The model performance on the IID and non-IID settings are shown in the figure below. We compare the performance of federated training to centralized and local training. To get a comprehensive view of the performance of federated training, for each client, we train a local model by using its local data alone. By comparing the performance of a local model and the federated model, we can study how much performance benefit a worker can achieve by participating in federated learning.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><img src="results.png" class="img-fluid" alt="Experiment Result"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Experiment Results</td>
</tr>
</tbody>
</table>
<p>The results of our experiments yield two important observations. Firstly, in the IID setting, the federated learning framework enables participants to collaboratively train malicious URL detectors with performance comparable to that of centralized trained classifiers. However, the performance improvement compared to local models is marginal. Secondly, in the non-IID setting, the three local models exhibit the worst performance. This is because the workers only have one type of malicious URLs in their training datasets, and their models cannot generalize to detect other types of malicious URLs. The results suggest that in the non-IID setting, clients can benefit significantly from collaborative training of malicious URL detectors with others, leading to significant performance improvements.</p>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-mcmahan2017communication" class="csl-entry" role="listitem">
McMahan, Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017. <span>“Communication-Efficient Learning of Deep Networks from Decentralized Data,”</span> 1273–82.
</div>
<div id="ref-zhao2018federated" class="csl-entry" role="listitem">
Zhao, Yue, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. 2018. <span>“Federated Learning with Non-Iid Data.”</span> <em>arXiv Preprint arXiv:1806.00582</em>.
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Last Update Aug. 2022
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>